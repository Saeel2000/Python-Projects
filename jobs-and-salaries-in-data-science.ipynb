{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7279972,"sourceType":"datasetVersion","datasetId":4213326}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/jobs-in-data/jobs_in_data.csv\")\ndata","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ac=data[data.employee_residence=='Germany']\nac","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ab= data[(data['employee_residence'] == \"Germany\") & (data['company_location'] == \"Germany\")]\nab","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for duplicates\nduplicates = data.duplicated().sum()\nprint(\"\\nNumber of duplicate rows:\", duplicates)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop duplicates if any\ndata_cleaned = data.drop_duplicates()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for any inconsistencies or errors in the data\n# For example, we can check for unique values in categorical columns\nprint(\"\\nUnique values in 'job_category' column:\", data_cleaned['job_category'].unique())\nprint(\"Unique values in 'experience_level' column:\", data_cleaned['experience_level'].unique())\nprint(\"Unique values in 'employment_type' column:\", data_cleaned['employment_type'].unique())\nprint(\"Unique values in 'work_setting' column:\", data_cleaned['work_setting'].unique())\nprint(\"Unique values in 'company_location' column:\", data_cleaned['company_location'].unique())\nprint(\"Unique values in 'company_size' column:\", data_cleaned['company_size'].unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'data' is your DataFrame\n# Create a copy of the DataFrame to avoid modifying the original data\ndata_copy = data.copy()\n\n# Optimize data types for memory usage\ndata_copy['work_year'] = pd.to_numeric(data_copy['work_year'], downcast='integer')\ndata_copy['job_title'] = data_copy['job_title'].astype('category')\ndata_copy['job_category'] = data_copy['job_category'].astype('category')\ndata_copy['salary_currency'] = data_copy['salary_currency'].astype('category')\ndata_copy['salary'] = pd.to_numeric(data_copy['salary'], downcast='integer')\ndata_copy['salary_in_usd'] = pd.to_numeric(data_copy['salary_in_usd'], downcast='integer')\ndata_copy['employee_residence'] = data_copy['employee_residence'].astype('category')\ndata_copy['experience_level'] = data_copy['experience_level'].astype('category')\ndata_copy['employment_type'] = data_copy['employment_type'].astype('category')\ndata_copy['work_setting'] = data_copy['work_setting'].astype('category')\ndata_copy['company_location'] = data_copy['company_location'].astype('category')\ndata_copy['company_size'] = data_copy['company_size'].astype('category')\n\n# Check the memory usage before and after optimization\nprint(\"Memory usage before optimization:\")\nprint(data.memory_usage(deep=True).sum() / (1024 * 1024), \"MB\")\n\nprint(\"\\nMemory usage after optimization:\")\nprint(data_copy.memory_usage(deep=True).sum() / (1024 * 1024), \"MB\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values\nmissing_values = data.isnull().sum()\nprint(\"\\nMissing Values:\")\nprint(missing_values)\n# Hence No missing values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize salary distribution\nplt.figure(figsize=(12, 6))\nsns.histplot(data['salary'], bins=20, kde=True)\nplt.title('Salary Distribution')\nplt.xlabel('Salary')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize job categories\nplt.figure(figsize=(12, 6))\nsns.countplot(y='job_category', data=data, order=data['job_category'].value_counts().index)\n# Add data labels\nfor index, value in enumerate(data['job_category'].value_counts()):\n    plt.text(value, index, str(value))\nplt.title('Job Categories')\nplt.xlabel('Count')\nplt.ylabel('Job Category')\nplt.legend(loc=1)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Average Salary by Job Category\navg_salary_by_category = data.groupby('job_category')['salary'].mean().sort_values(ascending=False)\nprint(\"\\nAverage Salary by Job Category:\")\nprint(avg_salary_by_category)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))  # Adjusted figure size to 8x6\nsns.countplot(x='experience_level', data=data, order=data['experience_level'].value_counts().index)\n\n# Add data labels\nfor index, value in enumerate(data['experience_level'].value_counts()):\n    plt.text(index, value, str(value), ha='center', va='bottom')\n\nplt.title('Distribution of Experience Levels')\nplt.xlabel('Experience Level')\nplt.ylabel('Count')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Employment Types Distribution\nplt.figure(figsize=(10, 6))\nsns.countplot(x='employment_type', data=data, order=data['employment_type'].value_counts().index)\n# Add data labels\nfor index, value in enumerate(data['experience_level'].value_counts()):\n    plt.text(index, value, str(value), ha='center', va='bottom')\nplt.title('Employment Types Distribution')\nplt.xlabel('Employment Type')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Company Sizes Distribution\nplt.figure(figsize=(8, 6))  # Adjusted figure size to 8x6\nsns.countplot(x='company_size', data=data, order=data['company_size'].value_counts().index)\n\n# Add data labels\nfor index, value in enumerate(data['company_size'].value_counts()):\n    plt.text(index, value, str(value), ha='center', va='bottom')\nplt.title('Company Sizes Distribution')\nplt.xlabel('Company Size')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Certainly! Here's a summary of the insights derived from the analysis of the job data:\n\n1. **Data Quality Check and Cleaning:**\n   - The dataset was loaded and examined for basic information, including data types, missing values, and duplicates. No missing values were found, and duplicates were removed from the dataset.\n\n2. **Memory Optimization:**\n   - Data types were optimized to reduce memory usage, improving the efficiency of data storage and processing.\n\n3. **Salary Distribution:**\n   - The distribution of salaries was visualized using a histogram, providing insights into the salary ranges across different job positions.\n\n4. **Job Categories Analysis:**\n   - The count of job categories was visualized, revealing the popularity of different job roles within the dataset.\n\n5. **Average Salary by Job Category:**\n   - The average salary for each job category was calculated, highlighting differences in salary levels across various job roles.\n\n6. **Experience Level Distribution:**\n   - The distribution of experience levels among employees was visualized, showing the distribution of workforce experience within the dataset.\n\n7. **Employment Types and Company Sizes:**\n   - The distribution of employment types and company sizes was explored, providing insights into the diversity of employment structures and organizational sizes.\n\nOverall, the analysis provided valuable insights into salary distributions, job category preferences, and employment trends within the dataset. These insights can be utilized for workforce planning, salary benchmarking, and recruitment strategies, ultimately contributing to better decision-making processes in human resources and talent management.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}